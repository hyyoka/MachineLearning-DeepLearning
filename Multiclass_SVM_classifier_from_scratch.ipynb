{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass SVM classifier from scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyyoka/DeepLearning-models-Implemetation-from-scratch/blob/main/Multiclass_SVM_classifier_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxx8RNoe7upv"
      },
      "source": [
        "# Multiclass SVM classifier from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLqvk6YrIyro"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import scipy.special as sp\n",
        "import time\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "import seaborn as sns"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG1YFm5FBzA5"
      },
      "source": [
        "## Support Vector Machine\n",
        "\n",
        "Starting with binary classification, the goal of SVM is to find out the best separating hyperplane of dataset having two classes. In other words, SVM is to find maximized distance between $w^Tx_i^1 + b= 1, w^Tx_i^2 + b = -1$. Distance is inversely proportional to $\\parallel w \\parallel$. What we want to solve is:\n",
        "$$minimize \\frac{\\parallel w \\parallel^2}{2}$$\n",
        "$$subject\\ to\\ w^Tx_i^1 + b \\geq 1, w^Tx_i^2 + b \\leq -1$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vYiIgNix0Xe"
      },
      "source": [
        "\n",
        "### Soft Margin SVM: Hinge loss\n",
        "![images.png](data:image/png;base64,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)\n",
        "\n",
        "Allow some misclassified points by setting a slack variable $u_i$. Keep in mind that smaller $u_i$ is better. \n",
        "\n",
        "$$minimize \\frac{\\parallel w \\parallel^2}{2} + \\gamma\\sum_i u_i$$\n",
        "$$subject\\ to\\ w^Tx_i^1 + b \\geq 1-u_i, w^Tx_i^2 + b \\leq -1+u_i. u_i \\geq 0$$\n",
        "\n",
        "Using hyperparameter $\\gamma$, we can decide whether minimizing $w$ is prioritized or not. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMqxwjbRNX6u"
      },
      "source": [
        "iris =  sns.load_dataset('iris') \n",
        "X= iris.iloc[:,:4]\n",
        "y = iris.iloc[:,-1]\n",
        "\n",
        "scal = StandardScaler() #scaling\n",
        "X = scal.fit_transform(X)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyMSHOFHNX7R"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KnlaqAJNX7X"
      },
      "source": [
        "y_train = pd.get_dummies(y_train) #one hot encoding\n",
        "y_test = pd.get_dummies(y_test)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNJ0OyWsB47p"
      },
      "source": [
        "### Multiclass SVM\n",
        "\n",
        "Multiclass SVM can be easily decomposed as repeating SVM K times. The goal of each SVM procedure is to classify one-to-rest.   \n",
        "\n",
        "$$minimize \\frac{\\parallel w \\parallel^2}{2} + \\gamma\\sum_i u_i\\ subject\\ to ...$$\n",
        "$$w^Tx_i^1 + b \\geq 1-u_i, y_i=k$$\n",
        "$$w^Tx_i^2 + b \\leq -1+u_i, y_i \\neq k$$\n",
        "$$u_i \\geq 0$$\n",
        "$$for\\ each\\ class\\ k=1,...,K$$\n",
        "\n",
        "K SVMs can be combined into one big SVM.\n",
        "\n",
        "$$minimize \\sum_k \\frac{\\parallel w \\parallel^2}{2} + \\gamma\\sum_i\\sum_{k \\neq y_i} u_i\\$$\n",
        "\n",
        "$$subject\\ to ...$$\n",
        "\n",
        "$$w_{y_i}^Tx_i + b_{y_i} \\geq w_{k}^Tx_i + b_{k} +2 -u_i^k$$\n",
        "$$k \\neq y_i$$\n",
        "$$u_i^k \\geq 0$$\n",
        "\n",
        "\n",
        "At optimality, we have:\n",
        "$$u_i^k = max[2+(w_{k}^Tx_i + b_{k}) - (w_{y_i}^Tx_i + b_{y_i}), 0]$$\n",
        "\n",
        "In other words with score:\n",
        "$$u_i^k = max[2+ score_k - score_{y_i}, 0]$$\n",
        "\n",
        "So, the total hinge loss is:\n",
        "$$u_i = \\sum_{k \\neq y_i}max(2+ score_k - score_{y_i}, 0)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rehziOrhwSVj"
      },
      "source": [
        "```\n",
        "â€¢ Wb: W vector and b vector of size (num class*feat dim + num class).\n",
        " ```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkAo03i-NX7v"
      },
      "source": [
        "## Multi class SVM\n",
        "\n",
        "def svm_loss(Wb, x, y):\n",
        "\n",
        "    SVM_loss = 0\n",
        "    \n",
        "    n = x.shape[0] # dataset size\n",
        "    input_dim = x.shape[1]\n",
        "    num_class = y.shape[0]\n",
        "\n",
        "    Wb = np.reshape(Wb, (-1, 1))\n",
        "    b = Wb[-num_class:]\n",
        "    W = np.reshape(Wb[range(num_class * input_dim)], (num_class, input_dim))\n",
        "\n",
        "\n",
        "    for xi, yi in zip(x, y):\n",
        "        yi = np.argmax(yi)\n",
        "        xi = np.reshape(xi, (-1,1))\n",
        "        xWb = W.dot(xi) + b\n",
        "\n",
        "        losses = []\n",
        "    \n",
        "        # hinge loss\n",
        "        losses = [max(0, score[0] - xWb[yi][0] + 1) for score in xWb if score != xWb[yi]]\n",
        "        SVM_loss += sum(losses)\n",
        "\n",
        "    return SVM_loss\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9hpd6ZhFbhG"
      },
      "source": [
        "input_dim = X.shape[1]\n",
        "num_class = y.shape[0]\n",
        "\n",
        "wb = np.random.normal(0, 1, (input_dim * num_class + num_class)) \n",
        "result = minimize(svm_loss, wb, args=(X_train, y_train))\n",
        "\n",
        "Wb = result.x"
      ],
      "execution_count": 59,
      "outputs": []
    }
  ]
}